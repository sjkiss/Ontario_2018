# head(on18$id)
#
# #Adjust pilot id numbers for merging
# pilot$id<-pilot$id+37
# names(on18)
# names(pilot)
# #Merge
# on18 %>%
#   left_join(., pilot, by='id') %>%
#   select(-starts_with('notes'), -ends_with('feel1')) ->on18
# ##Change emotion variable names
# names(on18)
# on18$emotion_imm
# on18 %>%
#   mutate_at(., vars(contains('emotion_')), labelled, c('anger'=1, 'anticipation'=2, 'disgust'=3, 'fear'=4, 'joy'=5, 'sadness'=6, 'surprise'=7, 'trust'=8)) %>%
#   modify_at(., vars(contains('emotion')), as_factor)->on18
# names(on18)
# on18$emotion_fin
# library(tidytext)
# library(textdata)
#This line imports nrc from the web
#nrc<-get_sentiments('nrc')
#
on18$indivfin2
#### LSD ####
library(quanteda)
on18$fin.y
#source(here("Code/1_load_on18.R"))
#Now read in the spellchecked emotions file.
library(rio)
library(openxlsx)
out<-read.csv(here("Data/feelings_workfile_spellcheck.csv"))
#out<-import(here("Data/feelings_workfile_spellcheck_Aug27.xlsx"))
head(out)
out$indivfinfeel[14]
out$indivfinfeel[38]
on18$indivfinfeel %>%
map(., nchar) %>%
unlist() %>%
summary()
nrow(out)
nrow(on18)
mean(out$id)
mean(on18$id)
summary(on18$id)
summary(out$id)
length(on18$id)
length(out$id)
#Adjust the id#s
out$id<-out$id+37
head(out$id)
nrow(out)
nrow(on18)
#there is one extra row in on18 that did not get spellchecked. It doesn't look like a quality response, but it should be kept.
names(on18)
names(out)
summary(on18$id)
summary(out$id)
on18$immfeel
on18$indivfinfeel
#This file adds in spell-checked and piloted emotions files
on18$indivfinfeel[14]
on18$indivfinfeel[38]
#Note after this join indivfinfeel.x and immfeel.x ARE NOT SPELLCHECKED
#indivfinfeel.y and immfeel.y ARE SPELLCHECKED
on18 %>%
left_join(., out, by='id') -> on18
on18 %>%
rename(imm.x=immfeel.x, imm.y=immfeel.y, fin.x=indivfinfeel.x, fin.y=indivfinfeel.y)->on18
source(here("Code/1_load_on18.R"))
#Now read in the spellchecked emotions file.
library(rio)
library(openxlsx)
out<-read.csv(here("Data/feelings_workfile_spellcheck.csv"))
#out<-import(here("Data/feelings_workfile_spellcheck_Aug27.xlsx"))
head(out)
out$indivfinfeel[14]
out$indivfinfeel[38]
on18$indivfinfeel %>%
map(., nchar) %>%
unlist() %>%
summary()
nrow(out)
nrow(on18)
mean(out$id)
mean(on18$id)
summary(on18$id)
summary(out$id)
length(on18$id)
length(out$id)
#Adjust the id#s
out$id<-out$id+37
head(out$id)
nrow(out)
nrow(on18)
#there is one extra row in on18 that did not get spellchecked. It doesn't look like a quality response, but it should be kept.
names(on18)
names(out)
summary(on18$id)
summary(out$id)
on18$immfeel
on18$indivfinfeel
#This file adds in spell-checked and piloted emotions files
on18$indivfinfeel[14]
on18$indivfinfeel[38]
#Note after this join indivfinfeel.x and immfeel.x ARE NOT SPELLCHECKED
#indivfinfeel.y and immfeel.y ARE SPELLCHECKED
on18 %>%
left_join(., out, by='id') -> on18
on18 %>%
rename(imm.x=immfeel.x, imm.y=immfeel.y, fin.x=indivfinfeel.x, fin.y=indivfinfeel.y)->on18
on18$fin.y
source("Code/1_LSDprep_dec2017.R")
LSDprep_contr(on18$fin.y)
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
on18$imm.y.LSD
on18$fin.y.LSD<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$fin.y.LSD<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD<-LSDprep_dict_punct(on18$imm.y.LSD)
on18$fin.y.LSD
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
return(LSDprep_dict_punct(on18$fin.y.LSD))
View(LSDprep_dict_punct(on18$fin.y.LSD))
on18$fin.y.LSD1<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
on18 %>%
select(contains("imm.y.LSD"))
str_replace_all(o18$fin.y.LSD, pattern = "^", replacement = " ")
str_replace_all(on18$fin.y.LSD, pattern = "^", replacement = " ")
test<-LSDprep_dict_punct(on18$fin.y.LSD)
test
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
on18$imm.y.LSD1
on18 %>%
select(imm.y) %>%
slice(285)
on18 %>%
ungroup() %>%
select(imm.y) %>%
slice(285)
on18 %>%
ungroup() %>%
select(imm.y) %>%
slice(285) %>%
View()
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
on18$fin.y.LSD1<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
#Check that this worked
on18 %>%
select(contains("imm.y.LSD")) %>%
slice(196:198)
on18 %>%
ungroup() ->on18
on18 %>%   select(imm.y) %>%
slice(285) %>%
View()
#Check that this worked
on18 %>%
select(contains("imm.y.LSD")) %>%
slice(196:198)
#Check that this worked
on18 %>%
select(contains("imm.y.LSD1")) %>%
slice(197)
#Check that this worked
on18 %>%
filter(str_detect(ends_with("LSD1"), "xtoo"))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo"))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo")) %>%
select(contains(ends_with("LSD1")))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo")) %>%
select(imm.y.LSD1)
LSDprep_punctspace(on18$fin.y.LSD1)
on18$fin.y.LSD2<-LSDprep_punctspace(on18$fin.y.LSD1)
on18$imm.y.LSD2<-LSDprep_punctspace(on18$imm.y.LSD1)
on18 %>%
select(ends_with("LSD2"))
on18 %>%
select(ends_with("LSD2")) %>%
print(100)
on18 %>%
select(ends_with("LSD2")) %>%
print(n=100)
LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD2<-LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD2<-LSDprep_punctspace(on18$fin.y.LSD1)
on18$imm.y.LSD2<-LSDprep_punctspace(on18$imm.y.LSD1)
on18$fin.y.LSD3<-LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD3<-LSDprep_negation(on18$fin.y.LSD2)
on18$imm.y.LSD3<-LSDprep_negation(on18$imm.y.LSD2)
on18 %>%
select(ends_with("LSD3")) %>%
print(n=100)
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " ))
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " )) %>%
select(fin.y, fin.y.LSD3)
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " )) %>%
select(fin.y, fin.y.LSD3) %>% View()
#
LSDprep_dict(on18$fin.y.LSD3)
#
on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
on18 %>%
select(ends_with("LSD4")) %>%
View()
#
# on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
# on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
# on18 %>%
#   select(ends_with("LSD4")) %>%
#   View()
#
# on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
# on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
# on18 %>%
#   select(ends_with("LSD4")) %>%
#   View()
library(quanteda)
?tokens_lookup
#
on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
tokens(on18$fin.y.LSD4)
tokens_lookup(tokens(on18$fin.y.LSD4),
dictionary=data_dictionary_LSD2015)
data_dictionary_LSD2015
tokens_compound(tokens(on18$fin.y.LSD4))
tokens_compound(tokens(on18$fin.y.LSD4), data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm()
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm() %>%
dfm_lookup(., data=data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm() %>%
dfm_lookup(., data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm()
# Calculate # of words about financial situation for each respnodeont
?tokens_compound
txt <- "The United Kingdom is leaving the European Union."
toks <- tokens(txt, remove_punct = TRUE)
toks
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
ntokens()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
ntoken()
# Calculate # of words about financial situation for each respnodeont
on18$fin.y.n<-tokens(on18$fin.y.LSD4) %>%
ntoken()
on18$imm.y.n<-tokens(on18$imm.y.LSD4) %>%
ntoken()
on18 %>%
select(ends_with(".n"))
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop")
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
data.frame()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
data.frame() %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
convert(., to="data.frame")
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
imm_dfm
fin_dfm
imm_dfm
fin_dfm
on18$fin.y
on18$fin.y[1:5,]
on18$fin.y[1:5]
fin_dfm
on18$fin.y[1:5]
on18$fin.y[1:5]
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() ->fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() ->imm_dfm
topfeatures(fin_dfm)
tokens_lookup(fin_dfm, dictionary=data_dictionary_LSD2015)
dfm_lookup(fin_dfm, dictionary=data_dictionary_LSD2015)
?kwic
kwic(fin_dfm, pattern=data_dictionary_LSD2015)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
nrow(on18)
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
imm_dfm
nrow(on18)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
tokens (on18$fin.y.LSD4)
tokens_lookup(tokens(on18$fin.y.LSD4))
tokens_lookup(tokens(on18$fin.y.LSD4), dictionary=data_dictionary_LSD2015)
tokens_lookup(tokens(on18$fin.y.LSD4),
dictionary=data_dictionary_LSD2015)
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)[4,]
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)[4:5,]
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
#Why is Item 4 showing now only one negative
colSums(fin_dfm)
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens (on18$imm.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
fin_dfm
fin_dfm %>%
convert(., to="data.frame")
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative)
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative) %>%
select(fin_sentiment)
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative) %>%
select(fin_sentiment) %>%
bind_cols(on18, .)->on18
#Repeat with immigration sentiment
imm_dfm %>%
convert(., to="data.frame") %>%
mutate(imm_sentiment=positive-negative) %>%
select(imm_sentiment) %>%
bind_cols(on18, .)->on18
cor(on18$fin_sentiment, on18$imm_sentiment)
names(on18)
on18$Social_Use2
on18$Social_Use
table(on18$Social_Use, on18$Social_Use2)
table(on18$Social_Use2)
table(on18$Social_Use)
on18 %>%
select(Social_Use2)
on18 %>%
select(Social_Use2, ends_with("sentiment"))
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T))
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
pivot_wider(., names_from = name, values_from=Average)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(~name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
filter(!is.na(Social_Use2)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(~name)
lm(fin_sentiment~Social_Use2, data=on18)
lm(imm_sentiment~Social_Use2, data=on18)
summary(lm(imm_sentiment~Social_Use2, data=on18))
names(on18)
on18$Media
lm(fin_sentiment~Media, data=on18)
summary(lm(fin_sentiment~Media, data=on18))
summary(lm(imm_sentiment~Media, data=on18))
