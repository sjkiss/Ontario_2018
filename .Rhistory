Social_Use2 == "About once a week"  |
Social_Use2 == "Several times a month")) %>%
select(policy_polarization)
# low social use
policy_rarely <- on18 %>%
filter((Social_Use2 == "Several times in a year" |
Social_Use2 == "Never" | Social_Use2 == "About once a month")) %>%
select(policy_polarization)
bimodality_coefficient(policy_often, na.rm = T)
bimodality_coefficient(policy_rarely, na.rm = T)
#### Affective Polarization Wagner (2021) ####
#Extract feelings towards parties scores
# on18 %>%
#   select(starts_with("partyeval")) %>%
#   glimpse()
# so it looks like I took the step sometime of
# scaling these variables to 0 and 1, and they end in
# _out.
# on18 %>%
#   select(starts_with("partyeval")) %>%
#   summary()
#Looks like the originals run from 0 to 5
# on18 %>%
#   select(starts_with("partyeval")) %>%
#   val_labels()
# on18 %>%
#   select(starts_with("partyeval")) %>%
#   var_label()
#Party Numbers
#4 is Green
# 1 is Liberal
# 3 is NDP
# 2 is OPC
# 0 (0) is Really dislike and 5 (1) is really like.
#Extract _out and create a new dataset to calculate affective polarization scores
on18 %>%
select(id,starts_with("partyeval")&ends_with("out"))->affect
on18 <- on18 %>%
rename(Green_Like = partyeval_4_out,
Liberal_Like = partyeval_1_out,
NDP_Like = partyeval_3_out,
PC_Like = partyeval_2_out)
names(affect)
affect %>%
rename(Green_Like=2, Liberal_Like=3, NDP_Like=4, PC_Like=5)->affect
#Create a new dataset for the weighted score
affect_wt <- affect
#For each respondent, we will need an average like for the parties
# This is mean(like)_i
#So we need to effectively calculate a mean for each row.
#Each row is one R.
# This is a billion times faster
# Never use c_across(). Banish it.
affect %>%
mutate(mean_like=rowMeans(across(2:5), na.rm=T))->affect
# affect %>%
#   rowwise() %>%
#   mutate(mean_like=mean(c_across(2:5), na.rm=T))->affect
#Now we need to take each R's like score for each party
# And subtract the mean from it.
affect_pol_cal <- affect %>%
pivot_longer(cols = !c(id, mean_like),
names_to = "Party",
values_to = "Party_like_score")
affect_pol_cal
affect_pol_cal$like_mean <- (affect_pol_cal$Party_like_score - affect_pol_cal$mean_like)^2
affect_pol_cal %>%
group_by(id) %>%
summarise(Soc_dis = sum(like_mean)) -> Soc_dis_scores
Soc_dis_scores$Soc_dis <- sqrt(Soc_dis_scores$Soc_dis/4)
full_join(on18, Soc_dis_scores, by = join_by(id)) -> on18
PARTIES <- c("Green_Like", "Liberal_Like", "NDP_Like", "PC_Like")
on18$Spread <- unweighted_like_scores(PARTIES, on18)
PARTIES <- c("Green_Like", "Liberal_Like", "NDP_Like", "PC_Like")
on18$Spread <- unweighted_like_scores(PARTIES, on18)
on18 <- on18 %>%
mutate(Spread_sd = scale(Spread))
#### Weighted Affective Polarization (WAP) Scores ####
affect_wt$Green_Like_wt <- (affect$Green_Like * 0.046)
affect_wt$PC_Like_wt <- (affect$PC_Like * 0.405)
affect_wt$Liberal_Like_wt <- (affect$Liberal_Like * 0.196)
affect_wt$NDP_Like_wt <- (affect$NDP_Like * 0.336)
affect_wt %>%
mutate(mean_like=rowMeans(across(6:9), na.rm=T))->affect_wt
# affect_wt %>%
#   rowwise() %>%
#   mutate(mean_like=mean(c_across(6:9), na.rm=T))->affect_wt
affect_pol_cal_wt <- affect_wt %>%
select(., !(6:9)) %>%
pivot_longer(cols = !c(id, mean_like),
names_to = "Party",
values_to = "Party_like_score")
affect_pol_cal_wt %>%
mutate(vote_share=case_when(Party == "Green_Like" ~ 0.046, Party == "Liberal_Like" ~ 0.196, Party == "NDP_Like" ~ 0.336,
Party == "PC_Like" ~ 0.405
)) -> affect_pol_cal_wt
affect_pol_cal_wt$like_mean <- (affect_pol_cal_wt$Party_like_score - affect_pol_cal_wt$mean_like)^2
affect_pol_cal_wt$like_mean_wt <- (affect_pol_cal_wt$like_mean * affect_pol_cal_wt$vote_share)
affect_pol_cal_wt %>%
group_by(id) %>%
summarise(WAP = sum(like_mean_wt)) -> WAP_scores
WAP_scores$WAP <- sqrt(WAP_scores$WAP)
full_join(on18, WAP_scores, by = join_by(id)) -> on18
on18 <- on18 %>%
mutate(
WAP_sd = as.numeric(scale(WAP))
)
#Get interest by media consunption
on18 %>%
group_by(Primary_media) %>%
summarise(mean = mean(pointerst_ONint, na.rm = T), sd = sd(pointerst_ONint, na.rm = T))
on18 %>%
group_by(Social_Use2) %>%
summarise(mean = mean(WAP, na.rm = T), sd = sd(WAP, na.rm = T))
#### WAP Leaders ####
#leader 1 Ford, leader 2 Horwath, leader 3 Schreiner, leader 4 Wynne
leader_affect <- on18 %>%
select(c(id, leadereval_1_out:leadereval_4_out)) %>%
rename(
Ford = leadereval_1_out,
Horwath = leadereval_2_out,
Schreiner = leadereval_3_out,
Wynne = leadereval_4_out
)
leader_affect$Schreiner_Like_wt <- (leader_affect$Schreiner * 0.046)
leader_affect$Ford_Like_wt <- (leader_affect$Ford * 0.405)
leader_affect$Wynne_Like_wt <- (leader_affect$Wynne * 0.196)
leader_affect$Horwath_Like_wt <- (leader_affect$Horwath * 0.336)
#
leader_affect %>%
mutate(mean_like=rowMeans(across(6:9), na.rm=T))->leader_affect
# leader_affect %>%
#   rowwise() %>%
#   mutate(mean_like=mean(c_across(6:9), na.rm=T))->leader_affect
leader_affect <- leader_affect %>%
select(., !(6:9)) %>%
pivot_longer(cols = !c(id, mean_like),
names_to = "Leader",
values_to = "Leader_like_score")
leader_affect %>%
mutate(vote_share=case_when(Leader == "Schreiner" ~ 0.046, Leader == "Wynne" ~ 0.196, Leader == "Horwath" ~ 0.336,
Leader == "Ford" ~ 0.405
)) -> leader_affect
leader_affect$like_mean <- (leader_affect$Leader_like_score - leader_affect$mean_like)^2
leader_affect$like_mean_wt <- (leader_affect$like_mean * leader_affect$vote_share)
leader_affect %>%
group_by(id) %>%
summarise(WAP_lead = sum(like_mean_wt)) -> leader_affect
leader_affect$WAP_lead <- sqrt(leader_affect$WAP_lead)
full_join(on18, leader_affect, by = join_by(id)) -> on18
on18$wap_difference <- on18$WAP - on18$WAP_lead
on18 <- on18 %>%
mutate(
WAP_lead_sd = as.numeric(scale(WAP_lead))
)
mean(on18$wap_difference, na.rm = T)
#### DESCRIPTIVE STATISTICS ####
#### Primary Media ####
#Descriptive Statistics for political knowledge by Primary media
table(on18$Social_Use2, on18$pol_knowledge)
on18 %>%
group_by(Primary_media) %>%
summarise(mean = mean(pol_knowledge, na.rm = T), sd = sd(pol_knowledge, na.rm = T))
#### Primary Media and Media source ####
on18$HuffingtonPostonline
media_Sources_by_primarymedia <- on18 %>%
group_by(Primary_media) %>%
summarise(across(CBCTV:HuffingtonPostonline, \(x)mean(x))) %>%
filter(Primary_media == "Online") %>%
pivot_longer(cols = 2:22)
#see the most read sources for online news users
media_Sources_by_primarymedia %>%
ggplot(aes(y = fct_reorder(name, value), x = value)) + geom_point()
#### Affective Polarization ####
on18 %>%
group_by(Social_Use2) %>%
summarise(mean = mean(WAP, na.rm = T), sd = sd(WAP, na.rm = T), n=n(), se=sd/sqrt(n))->mean_affect_scores
(on18 %>%
group_by(partyvote2018) %>%
summarise(Mean = mean(WAP, na.rm = T), Standard_Deviation = sd(WAP, na.rm = T), Minimum = min(WAP, na.rm = T), Maximum = max(WAP, na.rm = T), N=n()) %>%
rename(Group = partyvote2018) -> affect_scores_party)
(on18 %>%
group_by(Primary_media) %>%
summarise(Mean = mean(WAP, na.rm = T), Standard_Deviation = sd(WAP, na.rm = T), Minimum = min(WAP, na.rm = T), Maximum = max(WAP, na.rm = T), N=n()) %>%
rename(Group = Primary_media) -> affect_scores_primary_media)
mean(on18$WAP, na.rm = T); sd(on18$WAP, na.rm = T)
descripts_WAP <- rbind(tibble(Group = "Ontarians", Mean = mean(on18$WAP, na.rm = T),
Standard_Deviation = sd(on18$WAP, na.rm = T),
Minimum = min(on18$WAP, na.rm = T),
Maximum = max(on18$WAP, na.rm = T),
N = (length(!is.na(on18$WAP)))),
on18 %>%
group_by(Social_Use2) %>%
summarise(Mean = mean(WAP, na.rm = T), Standard_Deviation = sd(WAP, na.rm = T), Minimum = min(WAP, na.rm = T), Maximum = max(WAP, na.rm = T), N=n()) %>%
rename(Group = Social_Use2), affect_scores_party, affect_scores_primary_media)
#kableExtra::kable(descripts_WAP, format = "pipe", digits = 3)
tibble(Group = "Ontarians", Mean = mean(on18$WAP, na.rm = T),
Standard_Deviation = sd(on18$WAP, na.rm = T),
Minimum = min(on18$WAP, na.rm = T),
Maximum = max(on18$WAP, na.rm = T),
N = (length(!is.na(on18$WAP))))
mean_affect_scores
mean_affect_scores %>%
filter(complete.cases(.)) %>%
ggplot(., aes(x = mean,
y = Social_Use2,
colour = Social_Use2)) +
geom_point()+
geom_errorbar(aes (xmin = mean - (1.96*se), xmax = mean + (1.96*se)), width =.2) +
labs(x = "Mean", y= "Social Media Use") +
theme_bw()  +
theme(axis.text.y=element_blank(),
axis.ticks.y = element_blank(),
strip.text = element_text(size=8))+
guides(color=guide_legend(reverse=T))+xlim(c(0,0.5)) -> affect_scores_social_use; affect_scores_social_use
on18 %>%
group_by(Primary_media) %>%
summarise(mean = mean(Soc_dis, na.rm = T), sd = sd(Soc_dis, na.rm = T))
#### RE-RUN MAIN ANALYSES WITHOUT STRAIGHT LINERS ####
COVARS <- c("Interest", "age3", "degree", "income3", "pol_knowledge")
# WAP_primary_media <- list()
# for(i in 1:length(COVARS)){
#   data <- on18 |> filter(straightliner == 0)
#   WAP_primary_media[[i]] <-  lm_robust(reformulate(c("Primary_media", COVARS[1:i]),
#                                                    response = "WAP_sd"), data = data, se_type = "HC0")
# }
# lm_robust(reformulate(c("Primary_media"),
#                       response = "WAP_sd"), data = data, se_type = "HC0")
# modelsummary(WAP_primary_media, stars = T)
#### Policy Position Distribution ####
#Exploratory factor analysis
# cor_policies <- on18 %>%
#   dplyr::select(c(help_racial_minorities, help_women, more_coporate_tax,
#                     more_personal_tax, income_inequality, drug_benefit_u25, free_post_secondary,
#                     lr_private_health_care, Lr_minimum_wage_to_high_prices, lr_business_benefits_everyone,
#                     lr_inappropriate_sex_ed
#   )) %>%
#   cor(., use = "complete.obs")
#
#
# eigen(cor_policies)$values
# (policy_fa_analysis <- psych::fa(cor_policies, nfactors = 3))
#
# policy_issues <- 'policy =~ help_racial_minorities + help_women + more_coporate_tax +
#                                   more_personal_tax + income_inequality + drug_benefit_u25 + free_post_secondary +
#                                  lr_private_health_care + Lr_minimum_wage_to_high_prices + lr_business_benefits_everyone +
#                                   lr_inappropriate_sex_ed'
# cfa_policies <- cfa(policy_issues, data = on18)
# summary(cfa_policies, fit.measures = T, standardized = T)
#### REGRESION MODELS ####
lookfor(on18, "id")
on18 %>%
select(pidON, pidstrngthON) %>%
val_labels()
on18$Interest
#summary(lm(Interest~partisan, data=on18))
on18 %>%
ggplot(., aes(x=partisan, y=Interest))+geom_boxplot()
#| label: appendix-2
#| tbl-cap: OLS regressions of weighted affective polarization on social media usage plus controls
WAP_models %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female"), output="kableExtra") %>%
#cols_width(1~pct(25)) %>%
#opt_vertical_padding(scale=0.25)
#landscape(margin="0.5in") %>%
kable_styling(latex_options="scale_down")
#| label: setup
#| echo: false
library(knitr)
opts_knit$set(root.dir=rprojroot::find_rstudio_root_file())
#opts_chunk$set(warning=F,message=F)
#| label: import
#| echo: false
#| warning: false
#| message: false
#| results: 'hide'
#| output: false
library(here)
source(here("Code/3_polarization.R"))
source(here("Code/3a_bimodality_coefficients.R"))
#Cache needs to be turned off the render
#| label: overlapping
#| echo: false
#| warning: false
#| message: false
#| results: 'hide'
#| output: false
#| cache: true
library(here)
source(here("Code/3a_overlapping.R"))
#| label: set-theme
theme_set(theme_bw())
#| label: tbl-vote-choice
#| tbl-cap: Vote intention of all respondents.
data.frame(Party=c("Liberal Party of Ontario", "Progressive Conservative Party of Ontario",
"New Democratic Party of Ontario",
"Green Party of Ontario"), Vote=c(0.196, 0.405, 0.336, 0.046), Sample=rep("Election", 4))->vote_shares
library(gtsummary)
on18 %>%
as_factor() %>%
filter(partyvote2018!="Undecided") %>%
group_by(partyvote2018) %>%
summarize(n=n()) %>%
mutate(Vote=(n/sum(n)), Sample=rep("OPES", nrow(.))) %>%
select(-n, Party=partyvote2018) %>%
bind_rows(., vote_shares) %>%
mutate(Vote=scales::percent(Vote, accuracy=1)) %>%
pivot_wider(., names_from="Sample", values_from="Vote") %>%
kable()
#| label: calculate-spearman
#install.packages("pspearman")
spear1<-pspearman::spearman.test(as.ordered(on18$Social_Use2),as.ordered(on18$Primary_media))
#spear1$estimate
#| label: tbl-cross
#| tbl-cap: "Cross-tabulation of primary source of election news by frequency of general social media usage. Percentages are column percentages. Spearman's Rho correlation coefficient is 0.24"
#| eval: true
on18 %>%
tbl_cross(Social_Use2, Primary_media, percent="column")
#| echo: false
#| warning: false
#| fig-cap: Theoretical distibutions representing various levels of bimodality
#| label: fig-sim_bimod
#| fig-width: 8
#| fig-height: 4
ggarrange(uni_modal, semi_modal, bimodal, nrow = 1)
#| label: tbl-descript
#| tbl-cap: Summary of weighted affective polarization by media use
#| echo: false
#| message: false
library(gtsummary)
on18 %>%
select(WAP, Primary_media, Social_Use2) %>%
#filter(!is.na(Vote)) %>%
tbl_continuous(variable=c(WAP),
statistic=list(~"{mean} ({sd})"))
#| echo: false
#| warning: false
#| fig-cap: OLS Regression Models for Weighted Affective Polarization Scores by Media Consumption of Campaign News and Control Variables
#| label: fig-PM-models
#| fig-height: 8
WAP_models %>%
filter(Variable=="Primary_media") %>%
#Filter out the interaction model
filter(Model_Name!="Model 12") %>%
filter(str_detect(term, "Intercept", negate=T))  %>%
ggplot(., aes(x=estimate, y=fct_relevel(term, "Social_Media", "Online", "Mixed", after=10)))+
facet_wrap(~fct_relevel(Model_Name, "Model 10", "Model 11", "Model 12", "Model 13", "Model 14",  "Model 15", after=10))+
geom_pointrange(aes(xmin=estimate-(1.96*std.error), xmax=estimate+(1.96*std.error)))+geom_vline(xintercept=0, linetype=2, col="red")+labs(y="Variable", x="Coefficient")
#| echo: false
#| warning: false
#| fig-cap: OLS regression models coefficients for weighted affective polarization scores by social media usage and control variables. "Never" using social media is the reference category for self-reported social media usage.
#| fig-height: 8
#| label: fig-SU-models
WAP_models %>%
filter(Variable=="Social_Use2") %>%
filter(Model_Name!="Model 12") %>%
filter(str_detect(term, "Intercept", negate=T)) %>%
ggplot(., aes(x=estimate, y=fct_relevel(term, "Never", "Several times a day","About once a day","Several times a week","About once a week", "Less than once a week", after=7)))+
facet_wrap(~fct_relevel(Model_Name, "Model 10", "Model 11", "Model 12", "Model 13", "Model 14", "Model 15", after=10))+
geom_pointrange(aes(xmin=estimate-(1.96*std.error), xmax=estimate+(1.96*std.error)))+geom_vline(xintercept=0, linetype=2, col="red")+labs(y="Variable", x="Coefficient")
#| label: fig-interactions
#| fig-cap: Predicted values of affective polarization by selected levels of social media use and interest in politics.
#| fig-width: 5
#| fig-height: 3
plot_predictions(model6_su,
condition=list("Interest", Social_Use2=c("Never", "About once a day", "Several times a day")), vcov=F)+
aes(linetype=Social_Use2, col=Social_Use2)+labs(y="Predicted WAP")+theme(legend.position="bottom")+
guides(col=guide_legend(ncol=2))
#| label: fig-mod-diversity
#| fig-width: 5
#| fig-height: 3
mod_diversity<-lm(media_diversity~Interest*Social_Use2, data=on18)
plot_predictions(mod_diversity,
condition=list("Interest", Social_Use2=c("Never", "About once a day", "Several times a day")), vcov=F)+theme(legend.position="bottom")+
guides(col=guide_legend(ncol=2))
#| label: tbl-descript-policy
#| tbl-cap: Summary of ideology by media consumption.
#| echo: false
#| message: false
library(gtsummary)
on18 %>%
select(policy_polarization, Primary_media, Social_Use2) %>%
#filter(!is.na(Vote)) %>%
tbl_continuous(variable=c(policy_polarization),
statistic=list(~"{mean} ({sd})"))
#| echo: false
#| warning: false
#| label: fig-BC-PM
#| fig-cap: Probability distributions of policy positions by primary media source
#|
gridExtra::grid.arrange(bimod_online, bimod_mixed,bimod_legacy, bimod_social)
#| label: tbl-primary-media-interest-bimodality
#| tbl-cap: Policy polarization bimodality coefficients by media consumption and political interest.
library(gt)
on18 %>%
group_by(Interest_cat,Primary_media, ) %>%
filter(!is.na(Interest_cat)) %>%
summarize(Bimodality=bimodality_coefficient(policy_polarization)) %>%
rename(Interest=Interest_cat) %>%
mutate(Bimodality=round(Bimodality,2)) %>%
gt()
#| label: tbl-bimodality-social-media-policy
#| echo: false
on18 %>%
group_by(Social_Use2) %>%
summarize(Bimodality=bimodality_coefficient(policy_polarization)) %>%
filter(!is.na(Social_Use2)) %>%
#arrange(., desc(Bimodality)) %>%
gt() %>%
fmt_number(., columns=2, decimals=2)
#| echo: false
#| warning: false
#| label: fig-BC-SU
#| fig-width: 3
#| fig-height: 4
#| fig-cap: Bimodality Coefficents and policy position distributions by social media usage
gridExtra::grid.arrange(bimod_often, bimod_rarely)
#| label: fig-OVL-PM
#| echo: false
#| warning: false
#| fig-align: center
#| fig-cap: Overlap coefficents by primary media source for news about the provincial election.
ggpubr::ggarrange(overlap_legacy, overlap_online, overlap_smedia, overlap_mixed)
#| echo: false
#| fig-align: "center"
#| fig-cap: "Overlap Coefficents by Social Media Usage"
#| warning: false
#| fig-width: 3
#| fig-height: 4
#| label: fig-OVL-SU
ggpubr::ggarrange(overlap_often, overlap_rarely, ncol = 1)
WAP_models %>%
filter(Variable=="Primary_media") %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female"), output="kableExtra") %>%
#cols_width(1~pct(25)) %>%
#opt_vertical_padding(scale=0.25)
#landscape(margin="0.5in") %>%
kable_styling(latex_options="scale_down")
WAP_models %>%
filter(Variable=="Primary_media") %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female"), output="kableExtra")
WAP_models %>%
filter(Variable=="Primary_media") %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female",
"ScoreMixed:Interest"="Media Consumption (Mixed)*Interest",
"ScoreOnline:Interest"="Media Consumption (Online)*Interest",
"ScoreSocial_Media:Interest"="Media Consumption (Social_Media)*Interest"), output="kableExtra")
WAP_models %>%
filter(Variable=="Primary_media") %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female",
"ScoreMixed"="News Consumption (Mixed)",
"ScoreOnline"="News Consumption (Online)",
"ScoreSocial_Media"="News Consumption (Social_Media)",
"ScoreMixed:Interest"="News Consumption (Mixed)*Interest",
"ScoreOnline:Interest"="News Consumption (Online)*Interest",
"ScoreSocial_Media:Interest"="News Consumption (Social_Media)*Interest"), output="kableExtra") %>%
#cols_width(1~pct(25)) %>%
#opt_vertical_padding(scale=0.25)
#landscape(margin="0.5in") %>%
kable_styling(latex_options="scale_down")
#| label: appendix-2
#| tbl-cap: OLS regressions of weighted affective polarization on social media usage plus controls
WAP_models %>%
slice(1) %>%
select(model1:model15) %>%
map(., ~.[[1]]) %>%
modelsummary(.,fmt=2, stars=T, gof_omit = c("AIC|BIC|Log.Lik.|R2 Adj.|RMSE"),
coef_rename=c("media_diversity"="Media Diversity",
"degree"="Degree",
"age3"="Age",
"pol_knowledge"="Political knowledge",
"income"="Income","as_factor(gender)Female"="Female"), output="kableExtra")
