on18$fin.y.LSD<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$fin.y.LSD<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD<-LSDprep_dict_punct(on18$imm.y.LSD)
on18$fin.y.LSD
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
return(LSDprep_dict_punct(on18$fin.y.LSD))
View(LSDprep_dict_punct(on18$fin.y.LSD))
on18$fin.y.LSD1<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
on18 %>%
select(contains("imm.y.LSD"))
str_replace_all(o18$fin.y.LSD, pattern = "^", replacement = " ")
str_replace_all(on18$fin.y.LSD, pattern = "^", replacement = " ")
test<-LSDprep_dict_punct(on18$fin.y.LSD)
test
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
on18$imm.y.LSD1
on18 %>%
select(imm.y) %>%
slice(285)
on18 %>%
ungroup() %>%
select(imm.y) %>%
slice(285)
on18 %>%
ungroup() %>%
select(imm.y) %>%
slice(285) %>%
View()
on18$fin.y.LSD<-LSDprep_contr(on18$fin.y)
on18$imm.y.LSD<-LSDprep_contr(on18$imm.y)
on18$fin.y.LSD1<-LSDprep_dict_punct(on18$fin.y.LSD)
on18$imm.y.LSD1<-LSDprep_dict_punct(on18$imm.y.LSD)
#Check that this worked
on18 %>%
select(contains("imm.y.LSD")) %>%
slice(196:198)
on18 %>%
ungroup() ->on18
on18 %>%   select(imm.y) %>%
slice(285) %>%
View()
#Check that this worked
on18 %>%
select(contains("imm.y.LSD")) %>%
slice(196:198)
#Check that this worked
on18 %>%
select(contains("imm.y.LSD1")) %>%
slice(197)
#Check that this worked
on18 %>%
filter(str_detect(ends_with("LSD1"), "xtoo"))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo"))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo")) %>%
select(contains(ends_with("LSD1")))
#Check that this worked
on18 %>%
filter(str_detect(imm.y.LSD1, "xtoo")) %>%
select(imm.y.LSD1)
LSDprep_punctspace(on18$fin.y.LSD1)
on18$fin.y.LSD2<-LSDprep_punctspace(on18$fin.y.LSD1)
on18$imm.y.LSD2<-LSDprep_punctspace(on18$imm.y.LSD1)
on18 %>%
select(ends_with("LSD2"))
on18 %>%
select(ends_with("LSD2")) %>%
print(100)
on18 %>%
select(ends_with("LSD2")) %>%
print(n=100)
LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD2<-LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD2<-LSDprep_punctspace(on18$fin.y.LSD1)
on18$imm.y.LSD2<-LSDprep_punctspace(on18$imm.y.LSD1)
on18$fin.y.LSD3<-LSDprep_negation(on18$fin.y.LSD2)
on18$fin.y.LSD3<-LSDprep_negation(on18$fin.y.LSD2)
on18$imm.y.LSD3<-LSDprep_negation(on18$imm.y.LSD2)
on18 %>%
select(ends_with("LSD3")) %>%
print(n=100)
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " ))
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " )) %>%
select(fin.y, fin.y.LSD3)
on18 %>%
filter(str_detect(fin.y, pattern = " (N|n)ot much " )) %>%
select(fin.y, fin.y.LSD3) %>% View()
#
LSDprep_dict(on18$fin.y.LSD3)
#
on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
on18 %>%
select(ends_with("LSD4")) %>%
View()
#
# on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
# on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
# on18 %>%
#   select(ends_with("LSD4")) %>%
#   View()
#
# on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
# on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
# on18 %>%
#   select(ends_with("LSD4")) %>%
#   View()
library(quanteda)
?tokens_lookup
#
on18$fin.y.LSD4<-LSDprep_dict(on18$fin.y.LSD3)
on18$imm.y.LSD4<-LSDprep_dict(on18$imm.y.LSD3)
tokens(on18$fin.y.LSD4)
tokens_lookup(tokens(on18$fin.y.LSD4),
dictionary=data_dictionary_LSD2015)
data_dictionary_LSD2015
tokens_compound(tokens(on18$fin.y.LSD4))
tokens_compound(tokens(on18$fin.y.LSD4), data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm()
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm() %>%
dfm_lookup(., data=data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm() %>%
dfm_lookup(., data_dictionary_LSD2015)
tokens_compound(tokens(on18$fin.y.LSD4),
data_dictionary_LSD2015) %>%
dfm()
# Calculate # of words about financial situation for each respnodeont
?tokens_compound
txt <- "The United Kingdom is leaving the European Union."
toks <- tokens(txt, remove_punct = TRUE)
toks
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
ntokens()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
ntoken()
# Calculate # of words about financial situation for each respnodeont
on18$fin.y.n<-tokens(on18$fin.y.LSD4) %>%
ntoken()
on18$imm.y.n<-tokens(on18$imm.y.LSD4) %>%
ntoken()
on18 %>%
select(ends_with(".n"))
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop")
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
data.frame()
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
data.frame() %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
convert(., to="data.frame")
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative)
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
imm_dfm
fin_dfm
imm_dfm
fin_dfm
on18$fin.y
on18$fin.y[1:5,]
on18$fin.y[1:5]
fin_dfm
on18$fin.y[1:5]
on18$fin.y[1:5]
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() %>%fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() ->fin_dfm
# Calculate # of words about financial situation for each respnodeont
tokens(on18$fin.y.LSD4) %>%
dfm() ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() ->imm_dfm
topfeatures(fin_dfm)
tokens_lookup(fin_dfm, dictionary=data_dictionary_LSD2015)
dfm_lookup(fin_dfm, dictionary=data_dictionary_LSD2015)
?kwic
kwic(fin_dfm, pattern=data_dictionary_LSD2015)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
nrow(on18)
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
imm_dfm
nrow(on18)
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
tokens (on18$fin.y.LSD4)
tokens_lookup(tokens(on18$fin.y.LSD4))
tokens_lookup(tokens(on18$fin.y.LSD4), dictionary=data_dictionary_LSD2015)
tokens_lookup(tokens(on18$fin.y.LSD4),
dictionary=data_dictionary_LSD2015)
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015) %>%
View()
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)[4,]
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)[4:5,]
# Note row 4 is showing two words that are returning negative and negative positive
# Row 5 is showing two words that are showing positive and positive.
# What are those words
kwic(tokens(on18$fin.y.LSD4), pattern=data_dictionary_LSD2015)
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
fin_dfm
#Why is Item 4 showing now only one negative
colSums(fin_dfm)
#Get proportion counts
tokens (on18$fin.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens (on18$imm.y.LSD4) %>%
dfm() %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
tokens(on18$fin.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->fin_dfm
tokens(on18$imm.y.LSD4) %>%
dfm() %>%
dfm_weight(., scheme="prop") %>%
dfm_lookup(., dictionary=data_dictionary_LSD2015) ->imm_dfm
fin_dfm
fin_dfm %>%
convert(., to="data.frame")
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative)
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative) %>%
select(fin_sentiment)
fin_dfm %>%
convert(., to="data.frame") %>%
mutate(fin_sentiment=positive-negative) %>%
select(fin_sentiment) %>%
bind_cols(on18, .)->on18
#Repeat with immigration sentiment
imm_dfm %>%
convert(., to="data.frame") %>%
mutate(imm_sentiment=positive-negative) %>%
select(imm_sentiment) %>%
bind_cols(on18, .)->on18
cor(on18$fin_sentiment, on18$imm_sentiment)
names(on18)
on18$Social_Use2
on18$Social_Use
table(on18$Social_Use, on18$Social_Use2)
table(on18$Social_Use2)
table(on18$Social_Use)
on18 %>%
select(Social_Use2)
on18 %>%
select(Social_Use2, ends_with("sentiment"))
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T))
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
pivot_wider(., names_from = name, values_from=Average)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(~name)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
filter(!is.na(Social_Use2)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(~name)
lm(fin_sentiment~Social_Use2, data=on18)
lm(imm_sentiment~Social_Use2, data=on18)
summary(lm(imm_sentiment~Social_Use2, data=on18))
names(on18)
on18$Media
lm(fin_sentiment~Media, data=on18)
summary(lm(fin_sentiment~Media, data=on18))
summary(lm(imm_sentiment~Media, data=on18))
source("~/OneDrive - Wilfrid Laurier University/projects_folder/ON18/Code/3_polarization.R", echo=TRUE)
warnings()
#### LOAD SCRIPTS ####
source("Code/1_load_on18.R") #clean and load dataset
source("Code/0_functions.R") #load custom functions and packages needed for these analyses
source("Code/2_LSD_emotions.R")
names(on18)
on18$fin_sentiment
on18$fin.y
#Correlate
cor(on18$fin_sentiment, on18$imm_sentiment)
on18 %>%
select(Social_Use2, ends_with("sentiment")) %>%
pivot_longer(-1) %>%
group_by(Social_Use2, name) %>%
summarize(Average=mean(value, na.rm=T)) %>%
filter(!is.na(Social_Use2)) %>%
ggplot(., aes(x=Social_Use2, y=Average))+geom_point()+facet_wrap(~name)
lm(fin_sentiment~Social_Use2, data=on18)
summary(lm(imm_sentiment~Social_Use2, data=on18))
#### LOAD SCRIPTS ####
source("Code/1_load_on18.R") #clean and load dataset
source("Code/0_functions.R") #load custom functions and packages needed for these analyses
source("Code/2_LSD_emotions.R")
#### LOAD SCRIPTS ####
source("Code/1_load_on18.R") #clean and load dataset
source("Code/0_functions.R") #load custom functions and packages needed for these analyses
source("Code/2_LSD_emotions.R")
source("Code/1_LSDprep_dec2017.R")
source("Code/2_add_emotion_variables.R")
source("Code/2_LSD_emotions.R")
source("Code/2_add_emotion_variables.R")
#### Export to SPSS File ####
names(on18)
#| label: setup
#| echo: false
library(knitr)
opts_knit$set(root.dir=rprojroot::find_rstudio_root_file())
#opts_chunk$set(warning=F,message=F)
#| label: import
#| echo: false
#| warning: false
#| message: false
#| results: 'hide'
#| output: false
source("Code/3_polarization.R", local = knitr::knit_global())
#### LOAD SCRIPTS ####
source("Code/1_load_on18.R") #clean and load dataset
source("Code/0_functions.R") #load custom functions and packages needed for these analyses
source("Code/2_LSD_emotions.R")
#| label: import
#| echo: false
#| warning: false
#| message: false
#| results: 'hide'
#| output: false
source("Code/3_polarization.R", local = knitr::knit_global())
#load libraries
library(tidyverse)
library(haven)
library(here)
library(labelled)
library(broom)
library(ggeffects)
library(modelsummary)
library(ggpubr)
#### Import Data####
on18<-read_sav(file=here("Data/Ontario ES 2018 LISPOP.sav"))
lookfor(dat, "Date")
lookfor(dat, "date")
lookfor("date", dat)
lookfor(on18, "date")
paste(format(min(on18$datestamp),"%B %d), format(max(on18$datestamp), "%d, %Y)) sep="-")
paste(format(min(on18$datestamp),"%B %d), format(max(on18$datestamp), "%d, %Y)), sep="-")
paste(format(min(on18$datestamp),"%B %d), format(max(on18$datestamp), "%d, %Y), sep="-")
nrow(on18)
paste(format(min(on18$datestamp),"%B %d"))
paste(
format(min(on18$datestamp),"%B %d"),
format(min(on18$datestamp),"%B %d"),
sep="-"
)
paste(
format(min(on18$datestamp),"%B %d"),
format(min(on18$datestamp),"%d"),
sep="-"
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%d"),
sep="-"
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%d %Y"),
sep="-"
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%d %Y"),
sep=","
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%B %d %Y"),
sep=","
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%B %d %Y"),
sep="-"
)
paste(
format(min(on18$datestamp),"%B %d"),
format(max(on18$datestamp),"%B %d, %Y"),
sep="-"
)
